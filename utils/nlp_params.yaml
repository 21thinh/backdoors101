batch_size: 32
test_batch_size: 100
lr: 0.001
momentum: 0.9
decay: 0.0005
epochs: 100
save_on_epochs: []
optimizer: Adam
log_interval: 10


scheduler: True


data: nlp

poisoning_proportion: 1.1
poison_number: 8
backdoor: True
alpha: 0.95
scale_threshold: 0.1

normalize: loss+

save_model: True
log: True
tb: False

random: False
gan: False
defense: True
transform_train: True

nc: False
smoothing: False

losses:
  - backdoor
  - normal
#  - sums
#  - nc_adv
#  - ewc
#  - latent
#  - latent_fixed

losses_scales:
  backdoor: 0.2
  normal: 1.0
  latent: 0.6
  nc_adv: 0.5
  latent_fixed: 0.2